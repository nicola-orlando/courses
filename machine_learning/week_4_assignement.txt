import pandas as pd
import numpy as np
from sklearn import metrics
from sklearn.model_selection import GridSearchCV

from sklearn.linear_model import LogisticRegression

def blight_model():
    
    df_train = pd.read_csv('train.csv',encoding='cp1252')
    df_test = pd.read_csv('test.csv',encoding='cp1252')
    df_test_orig = pd.read_csv('test.csv',encoding='cp1252')
    
    # Remove training features which we will not use as they are not available at testing time
    features_to_remove = ['payment_amount','payment_date',
                          'payment_status','balance_due','collection_status','compliance_detail'] 

    # Are all the remaining features any useful? 
    # Here a list of features which can't be that useful, based on reasoning, also minimising the input features 
    # multiplicity as much as possible
    uninteresting_features = ['violator_name', 'violation_street_number', 'ticket_id',
                              'mailing_address_str_number', 'mailing_address_str_name',
                              'non_us_str_code', 'ticket_issued_date', 'hearing_date', 'violation_description',
                              'violation_zip_code', 'disposition', 'grafitti_status',
                              'admin_fee', 'state_fee', 'clean_up_cost', 
                              'discount_amount', 'judgment_amount', 'violation_code']
    
    categorical_data_hm = ['violation_street_name', 'city', 'zip_code'] # not to be used anyway..
    other = ['agency_name', 'inspector_name', 'state', 'country'] # same
   
    # Convert categorical data objects into numbers
    categorical_data = ['agency_name', 'inspector_name', 'state', 'country', 'violation_code']
    for cat_data_to_cnv in categorical_data:
        #print ("Handling now data category "+cat_data_to_cnv)
        df_train[cat_data_to_cnv] = pd.Categorical(df_train[cat_data_to_cnv])
        df_test[cat_data_to_cnv] = pd.Categorical(df_test[cat_data_to_cnv])        
        df_train[cat_data_to_cnv] = df_train[cat_data_to_cnv].cat.codes
        df_test[cat_data_to_cnv] = df_test[cat_data_to_cnv].cat.codes
        
    features_to_remove = features_to_remove+uninteresting_features+categorical_data_hm+other
    for feature in features_to_remove:
        df_train.drop(feature, axis=1, inplace = True) 
    
    # Select only the features to keep in the test data. Use model with just two features 
    features_to_keep = ['fine_amount', 'late_fee',]
    features_test = list(df_test.columns)

    df_test = df_test.filter(features_to_keep, axis=1)
    variables = list(df_train.columns)
    
    df_train['compliance'].replace('nan', np.nan, inplace=True)
    columns = list(df_test.columns)
    for element in columns: 
        df_test[element].replace(np.nan, 0, inplace=True)
    
    # Remove nans afte getting rid of all unwanted columns 
    df_train.dropna(inplace = True)

    # Prepare the data to be used 
    y_train_series = df_train.pop('compliance')
    y_train = np.array(y_train_series)
    X_train = np.array(df_train)
    X_test = np.array(df_test)
    
    # Ensure weight class to be based on frequencies 
    cls = LogisticRegression(random_state=0, class_weight='balanced')
    # Simplest possible HP scan 
    parameters = {'C': [0.1,1,10]}
    clf = GridSearchCV(cls, param_grid=parameters, scoring='roc_auc')  
    clf.fit(X_train,y_train)
    y_train_score = clf.best_estimator_.predict(X_train)
    
    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_score)
    train_score = metrics.auc(fpr, tpr) 

    y_test_predict = clf.predict_proba(X_test)
    # Pass index corresponding to prob 1. 
    output = pd.Series(np.array(y_test_predict[:,1]), index = df_test_orig.ticket_id)
    return output # Your answer here